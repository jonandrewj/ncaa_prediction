{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Basic ML Learning Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The goal of this notebook is to look at just the ability of the seed number\n",
    "# to determine the winner. One caveat here is that the model always should be\n",
    "# correct when two teams of the same seed go head to head. I could fix it but\n",
    "# it probably isn't worth the effort. The accuracies seem to be about 70% or \n",
    "# maybe 65% considering the imperfect data. I also broke the learning down by\n",
    "# season just to see if we are potentially getting better at seeding teams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict( train, test, feat_cols, label_col, model ):\n",
    "    model.fit( train[feat_cols], train[label_col] )\n",
    "    return model.score( test[feat_cols], test[label_col] )\n",
    "\n",
    "def test_model( data, feat_cols, label_col, model ):\n",
    "    accs = []\n",
    "    for i in range(10):\n",
    "        train = data.sample( frac=.7 )\n",
    "        test = data.drop( train.index )\n",
    "        accs += [predict( train, test, feat_cols, label_col, model )]\n",
    "    return sum(accs) / len(accs)\n",
    "\n",
    "models = {  'LogReg': LogisticRegression(),\n",
    "            'DecisionTree': DecisionTreeClassifier( max_depth=5 ),\n",
    "            'NaiveBayes': GaussianNB(),\n",
    "            'NeuralNet': MLPClassifier(),\n",
    "            'RandomForest': RandomForestClassifier(),\n",
    "            'KNN': KNeighborsClassifier( 5 ),\n",
    "            'SVC': SVC(),\n",
    "            'BoostClassifier':AdaBoostClassifier() }\n",
    "\n",
    "def test_models( data, feat_cols, label_col ):\n",
    "    for model in models.keys():\n",
    "        accuracy = test_model( data, feat_cols, label_col, models[model] )\n",
    "        print( model, \": \", accuracy )\n",
    "        \n",
    "def test_ensemble( model_names, data, feat_cols, label_col ):\n",
    "    estimators = []\n",
    "    estimators.append( (model_names[0], models[model_names[0]]) )\n",
    "    for name in model_names:\n",
    "        estimators.append( (name + '1', models[name]) )\n",
    "        estimators.append( (name + '2', models[name]) )\n",
    "        \n",
    "    ensemble = VotingClassifier( estimators=estimators, voting='hard' )\n",
    "    accuracy = test_model( data, feat_cols, label_col, ensemble )\n",
    "    print( 'Ensemble: ', accuracy )\n",
    "        \n",
    "def normalize( data ): # STILL WORKING ON THIS\n",
    "    x = data.values #returns a numpy array\n",
    "    normalizer = preprocessing.MinMaxScaler()\n",
    "    x_scaled = normalizer.fit_transform( x )\n",
    "    return pandas.DataFrame( x_scaled, columns=data.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data\n",
      "LogReg :  0.715306122449\n",
      "DecisionTree :  0.66768707483\n",
      "NaiveBayes :  0.67074829932\n",
      "NeuralNet :  0.712585034014\n",
      "RandomForest :  0.65612244898\n",
      "KNN :  0.665306122449\n",
      "SVC :  0.697619047619\n",
      "BoostClassifier :  0.686394557823\n",
      "Ensemble:  0.719727891156\n",
      "2004\n",
      "NeuralNet 0.765625\n",
      "2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonandrewj/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.71875\n",
      "2006\n",
      "NaiveBayes 0.6875\n",
      "2007\n",
      "LogReg 0.8125\n",
      "2008\n",
      "LogReg 0.765625\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "# SOME BASIC TESTING ON SEEDING DATA AND RPI RANKINGS ############\n",
    "data = pandas.read_csv( 'cleaned/TourneySeedsAndRankings.csv' )\n",
    "half = data.sample( frac=.5 )\n",
    "rest = data.drop( half.index )\n",
    "half['Winner'] = 'A'\n",
    "rest['Winner'] = 'B'\n",
    "\n",
    "def rename( half, rest, winner_name, loser_name, generic_name ):\n",
    "    half = half.rename( index=str, columns={ winner_name: generic_name + '1', loser_name:  generic_name + '2'} )\n",
    "    rest = rest.rename( index=str, columns={ loser_name:  generic_name + '1', winner_name: generic_name + '2'} )\n",
    "    return half, rest\n",
    "\n",
    "cols = [ 'SAG', 'Seed', 'RPI', 'POM' ]\n",
    "for name in cols:\n",
    "    half, rest = rename( half, rest, 'W' + name, 'L' + name, name )\n",
    "    \n",
    "data = pandas.concat( [rest, half] )\n",
    "\n",
    "columns = []\n",
    "for name in cols:\n",
    "    columns.append( name + '1' )\n",
    "    columns.append( name + '2' )\n",
    "    \n",
    "for col in columns:\n",
    "    data[col] = data[col] - data[col].min()\n",
    "    data[col] = data[col] / data[col].max()\n",
    "    \n",
    "print( 'All Data' )\n",
    "test_models( data, columns, 'Winner' )\n",
    "test_ensemble( ['LogReg', 'NeuralNet', 'SVC'], data, columns, 'Winner' )\n",
    "\n",
    "years = {}\n",
    "for year in range(2004, 2018):\n",
    "    train = data.loc[ data['Season'] < year ]\n",
    "    test = data.loc[ data['Season'] == year ]\n",
    "    print( year )\n",
    "    results = {}\n",
    "    for model_name in models.keys():\n",
    "        acc = predict( train, test, columns, 'Winner', models[model_name])\n",
    "        results[model_name] = acc\n",
    "    best = max( results.keys(), key=(lambda k: results[k]) )\n",
    "    print(best, results[best])\n",
    "    years[year] = (best, results[best])\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.scatter( [year for year in years.keys()], [years[year][1] for year in years.keys()] )\n",
    "    \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg :  0.707482993197\n",
      "DecisionTree :  0.664965986395\n",
      "NaiveBayes :  0.665306122449\n",
      "NeuralNet :  0.714965986395\n",
      "RandomForest :  0.679591836735\n",
      "KNN :  0.67925170068\n",
      "SVC :  0.69387755102\n",
      "BoostClassifier :  0.684013605442\n",
      "Ensemble:  0.721768707483\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COL1</th>\n",
       "      <th>COL2</th>\n",
       "      <th>DOL1</th>\n",
       "      <th>DOL2</th>\n",
       "      <th>LBIH</th>\n",
       "      <th>LBOB</th>\n",
       "      <th>LCNG</th>\n",
       "      <th>LDOK</th>\n",
       "      <th>LDUN</th>\n",
       "      <th>LMAS</th>\n",
       "      <th>...</th>\n",
       "      <th>WLK2</th>\n",
       "      <th>WMAS</th>\n",
       "      <th>WPGH</th>\n",
       "      <th>WPIG</th>\n",
       "      <th>WSE</th>\n",
       "      <th>WSEL</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WWIL</th>\n",
       "      <th>WWOL</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065385</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.057823</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108392</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.092466</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.080268</td>\n",
       "      <td>49.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111888</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.133562</td>\n",
       "      <td>0.180272</td>\n",
       "      <td>0.163880</td>\n",
       "      <td>52.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129371</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>56.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031469</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.180769</td>\n",
       "      <td>0.071918</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.053512</td>\n",
       "      <td>41.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        COL1      COL2      DOL1      DOL2  LBIH  LBOB  LCNG  LDOK  LDUN  \\\n",
       "3   0.065385  0.116438  0.057823  0.120401  17.0  24.0   NaN   NaN  27.0   \n",
       "4   0.211538  0.092466  0.163265  0.080268  49.0  47.0   NaN   NaN  23.0   \n",
       "7   0.173077  0.133562  0.180272  0.163880  52.0  40.0   NaN   NaN  67.0   \n",
       "8   0.200000  0.047945  0.183673  0.036789  56.0  63.0   NaN   NaN  42.0   \n",
       "12  0.180769  0.071918  0.170068  0.053512  41.0  59.0   NaN   NaN  44.0   \n",
       "\n",
       "    LMAS   ...        WLK2  WMAS  WPGH  WPIG   WSE  WSEL  WTeamID  WWIL  WWOL  \\\n",
       "3   19.0   ...    0.108392  36.0   NaN   NaN  32.0  48.0     1141   NaN    49   \n",
       "4   48.0   ...    0.111888  30.0   NaN   NaN  30.0  28.0     1143   NaN    26   \n",
       "7   54.0   ...    0.129371  49.0   NaN   NaN  38.0  40.0     1211   NaN    43   \n",
       "8   51.0   ...    0.031469  11.0   NaN   NaN  16.0  10.0     1228   NaN    14   \n",
       "12  38.0   ...    0.066434  23.0   NaN   NaN  18.0  20.0     1323   NaN    18   \n",
       "\n",
       "    Winner  \n",
       "3        B  \n",
       "4        B  \n",
       "7        B  \n",
       "8        B  \n",
       "12       B  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASIC TESTING ON DIFFERENT TEAM STRENGTH RANKINGS ##############\n",
    "# I THINK WE CAN ADD PRE-PROCESSING BUT THIS LOOKS DECENT FOR NOW...\n",
    "data = pandas.read_csv( 'cleaned/TourneyResultsWithRankings.csv' )\n",
    "\n",
    "# DISSASOCIATE THE SEEDS AS WINNING OR LOSING ####################\n",
    "half = data.sample( frac=.5 )\n",
    "rest = data.drop( half.index )\n",
    "half['Winner'] = 'A'\n",
    "rest['Winner'] = 'B'\n",
    "\n",
    "def rename( half, rest, winner_name, loser_name, generic_name ):\n",
    "    half = half.rename( index=str, columns={ winner_name: generic_name + '1', loser_name:  generic_name + '2'} )\n",
    "    rest = rest.rename( index=str, columns={ loser_name:  generic_name + '1', winner_name: generic_name + '2'} )\n",
    "    return half, rest\n",
    "\n",
    "systems = [ 'RPI', 'POM', 'MOR', 'RTH', 'WLK', 'DOL', 'COL', 'SAG' ]\n",
    "for name in systems:\n",
    "    half, rest = rename( half, rest, 'W' + name, 'L' + name, name )\n",
    "\n",
    "data = pandas.concat( [rest, half] )\n",
    "\n",
    "\n",
    "columns = []\n",
    "for name in systems:\n",
    "    columns.append( name + '1' )\n",
    "    columns.append( name + '2' )\n",
    "    \n",
    "for col in columns:\n",
    "    data[col] = data[col] - data[col].min()\n",
    "    data[col] = data[col] / data[col].max()\n",
    "\n",
    "test_models( data, columns, 'Winner' )\n",
    "test_ensemble( ['LogReg', 'NeuralNet', 'SVC'], data, columns, 'Winner' )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg :  0.710236220472\n",
      "DecisionTree :  0.712440944882\n",
      "Gaussian :  0.71842519685\n",
      "NeuralNet :  0.72031496063\n",
      "RandomForest :  0.708976377953\n",
      "KNN :  0.680157480315\n",
      "SVC :  0.71937007874\n"
     ]
    }
   ],
   "source": [
    "# BASIC TESTING ON SEEDING DATA ##################################\n",
    "data = pandas.read_csv( 'cleaned/TourneyResultsWithSeeds.csv')\n",
    "\n",
    "# DISSASOCIATE THE SEEDS AS WINNING OR LOSING ####################\n",
    "half = data.sample( frac=.5 )\n",
    "rest = data.drop( half.index )\n",
    "half['Winner'] = 'A'\n",
    "rest['Winner'] = 'B'\n",
    "half = half.rename( index=str, columns={ 'WSeed':'Seed_One', 'LSeed':'Seed_Two'} )\n",
    "rest = rest.rename( index=str, columns={ 'LSeed':'Seed_One', 'WSeed':'Seed_Two'} )\n",
    "data = pandas.concat( [rest, half] )\n",
    "\n",
    "# TRAINING AND TESTING DATA ############\n",
    "feature_columns = ['Seed_One', 'Seed_Two']\n",
    "test_models( data, feature_columns, 'Winner' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
