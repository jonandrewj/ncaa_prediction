{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Basic ML Learning Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The goal of this notebook is to look at just the ability of the seed number\n",
    "# to determine the winner. One caveat here is that the model always should be\n",
    "# correct when two teams of the same seed go head to head. I could fix it but\n",
    "# it probably isn't worth the effort. The accuracies seem to be about 70% or \n",
    "# maybe 65% considering the imperfect data. I also broke the learning down by\n",
    "# season just to see if we are potentially getting better at seeding teams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTILITY FUNCTIONS FOR PRE-PROCESSING AND \n",
    "\n",
    "# INPUT: Train Dataframe, Test Dataframe, list(column names for training),\n",
    "# label_col - 'Winner', model - a machine learning model\n",
    "# RETURNS: the accuracy of the predictions\n",
    "def predict( train, test, feat_cols, label_col, model ):\n",
    "    model.fit( train[feat_cols], train[label_col] )\n",
    "    return model.score( test[feat_cols], test[label_col] )\n",
    "\n",
    "# INPUT: All the Data, feat_cols - list(columns to train on),\n",
    "# label_col - 'Winner', model - machine learning model\n",
    "def test_model( data, feat_cols, label_col, model ):\n",
    "    accs = []\n",
    "    for i in range(10):\n",
    "        train = data.sample( frac=.7 )\n",
    "        test = data.drop( train.index )\n",
    "        accs += [predict( train, test, feat_cols, label_col, model )]\n",
    "    return sum(accs) / len(accs)\n",
    "\n",
    "# MODELS FROM SKLEARN ################################################\n",
    "models = {  'LogReg': LogisticRegression(),\n",
    "            'DecisionTree': DecisionTreeClassifier( max_depth=5 ),\n",
    "            'NaiveBayes': GaussianNB(),\n",
    "            'NeuralNet': MLPClassifier(),\n",
    "            'RandomForest': RandomForestClassifier(),\n",
    "            'KNN': KNeighborsClassifier( 5 ),\n",
    "            'SVC': SVC(),\n",
    "            'BoostClassifier':AdaBoostClassifier() }\n",
    "\n",
    "# THIS FUNCTION TESTS THE ACCURACY OF THE DATA ON ALL THE MODELS #####\n",
    "def test_models( data, feat_cols, label_col ):\n",
    "    for model in models.keys():\n",
    "        accuracy = test_model( data, feat_cols, label_col, models[model] )\n",
    "        print( model, \": \", accuracy )\n",
    "\n",
    "# THIS FUNCTION TESTS AN ENSEMBLE ####################################\n",
    "# JUST GIVE IT A LIST OF MODEL NAMES AND IT WILL TRAIN THEM ALL AND ##\n",
    "# VOTE ON THEIR PREDICTIONS. THE FIRST MODEL IS THE TIE BREAKER ######\n",
    "def test_ensemble( model_names, data, feat_cols, label_col ):\n",
    "    estimators = []\n",
    "    estimators.append( (model_names[0], models[model_names[0]]) )\n",
    "    for name in model_names:\n",
    "        estimators.append( (name + '1', models[name]) )\n",
    "        estimators.append( (name + '2', models[name]) )\n",
    "        \n",
    "    ensemble = VotingClassifier( estimators=estimators, voting='hard' )\n",
    "    accuracy = test_model( data, feat_cols, label_col, ensemble )\n",
    "    print( 'Ensemble: ', accuracy )\n",
    "\n",
    "# THIS FUNCTION NORMALIZES THE DATA FOR THE COLUMNS GIVEN ############\n",
    "def normalize( data, col_names ):\n",
    "    for col in col_names:\n",
    "        data[col] = data[col] - data[col].min() # SUBTRACT THE MIN ###\n",
    "        data[col] = data[col] / data[col].max() # DIVIDE BY THE MAX ##\n",
    "    return data\n",
    "\n",
    "# THIS IS A HELPER FUNCTION FOR THE SCRAMBLE_WINNER FUNCTION #########\n",
    "# IT TAKES TWO HALVES OF THE DATA AND RENAMES THE COLUMNS APPROPRIATELY\n",
    "def rename( half, rest, winner_name, loser_name, generic_name ):\n",
    "    half = half.rename( index=str, columns={ winner_name: generic_name + '1', loser_name:  generic_name + '2'} )\n",
    "    rest = rest.rename( index=str, columns={ loser_name:  generic_name + '1', winner_name: generic_name + '2'} )\n",
    "    return half, rest\n",
    "\n",
    "# THE DATA IS JUST THE DATA, THE RENAME RULES ARE EACH A SET OF 3 ####\n",
    "# STRINGS - The columns names for the winner, loser, and the generic #\n",
    "# name they will get after scrambling ################################\n",
    "# FOR EXAMPLE: (WRPI, LRPI, RPI) => will rename WRPI and LRPI to #####\n",
    "# RPI1 and RPI2 ######################################################\n",
    "def scramble_winner( data, rename_rules ):\n",
    "    half = data.sample( frac=.5 )\n",
    "    rest = data.drop( half.index )\n",
    "    half['Winner'] = 'A'\n",
    "    rest['Winner'] = 'B'\n",
    "    \n",
    "    for rule in rename_rules:\n",
    "        half, rest = rename( half, rest, rule[0], rule[1], rule[2] )\n",
    "    \n",
    "    return pandas.concat( [rest, half] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data\n",
      "LogReg :  0.718367346939\n",
      "DecisionTree :  0.655782312925\n",
      "NaiveBayes :  0.705442176871\n",
      "NeuralNet :  0.707482993197\n",
      "RandomForest :  0.668707482993\n",
      "KNN :  0.662244897959\n",
      "SVC :  0.702040816327\n",
      "BoostClassifier :  0.693197278912\n",
      "Ensemble:  0.713265306122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonandrewj/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004 NeuralNet 0.6875\n",
      "2005 KNN 0.71875\n",
      "2006 LogReg 0.71875\n",
      "2007 LogReg 0.828125\n",
      "2008 LogReg 0.765625\n",
      "2009 BoostClassifier 0.765625\n",
      "2010 LogReg 0.703125\n",
      "2011 NaiveBayes 0.671641791045\n",
      "2012 DecisionTree 0.731343283582\n",
      "2013 RandomForest 0.716417910448\n",
      "2014 DecisionTree 0.671641791045\n",
      "2015 LogReg 0.746268656716\n",
      "2016 NaiveBayes 0.731343283582\n",
      "2017 LogReg 0.761194029851\n",
      "\n",
      "   LTeamID      POM1      POM2      RPI1      RPI2      SAG1      SAG2  \\\n",
      "0     1411  0.908163  0.858044  0.755245  0.708812  0.833876  0.825083   \n",
      "1     1436  0.486395  0.006309  0.500000  0.003831  0.511401  0.003300   \n",
      "5     1166  0.088435  0.154574  0.076923  0.164751  0.055375  0.155116   \n",
      "7     1140  0.085034  0.069401  0.062937  0.103448  0.087948  0.072607   \n",
      "9     1161  0.292517  0.022082  0.258741  0.042146  0.286645  0.029703   \n",
      "\n",
      "   Season     Seed1     Seed2  WTeamID Winner  \n",
      "0    2003  1.000000  1.000000     1421      B  \n",
      "1    2003  1.000000  0.000000     1112      B  \n",
      "5    2003  0.333333  0.666667     1141      B  \n",
      "7    2003  0.733333  0.266667     1163      B  \n",
      "9    2003  0.866667  0.133333     1181      B  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzNLnBDMzAyA/w+pjqjRRiOIYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09b71758d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOME BASIC TESTING ON SEEDING DATA AND RPI RANKINGS ################\n",
    "# IMPORT THE DATA ####################################################\n",
    "data = pandas.read_csv( 'cleaned/TourneySeedsAndRankings.csv' )\n",
    "\n",
    "# COLUMNS THAT I AM INTERESTED IN LEARNING ON ########################\n",
    "cols = [ 'SAG', 'Seed', 'RPI', 'POM' ]\n",
    "\n",
    "# SET UP THE RULES FOR RENAMING SO THAT THE WINNER DATA CAN BE #######\n",
    "# SCRAMBLED ##########################################################\n",
    "rules = []\n",
    "for col in cols:\n",
    "    rules.append( ('W' + col, 'L' + col, col) )\n",
    "\n",
    "# SCRAMBLE THE WINNER FROM THE DATA ##################################\n",
    "data = scramble_winner( data, rules )\n",
    "\n",
    "# SET UP MY LABEL COLUMNS ############################################\n",
    "label_cols = []\n",
    "for name in cols:\n",
    "    label_cols.append( name + '1' )\n",
    "    label_cols.append( name + '2' )\n",
    "\n",
    "# NORMALIZE MY DATA ##################################################\n",
    "data = normalize(data, label_cols)\n",
    "   \n",
    "# PERFORM TESTS ON MY DATA ###########################################\n",
    "print( 'All Data' )\n",
    "\n",
    "# TEST ALL THE DATA FOR ALL THE MODELS AND THEN WITH AN ENSEMBLE #####\n",
    "test_models( data, label_cols, 'Winner' )\n",
    "test_ensemble( ['LogReg', 'NeuralNet', 'SVC'], data, label_cols, 'Winner' )\n",
    "print()\n",
    "\n",
    "# TEST TO SEE THE PREDICTION ACCURACY FOR EACH YEAR ##################\n",
    "years = {}\n",
    "for year in range(2004, 2018):\n",
    "    train = data.loc[ data['Season'] < year ]\n",
    "    test = data.loc[ data['Season'] == year ]\n",
    "    results = {}\n",
    "    for model_name in models.keys():\n",
    "        acc = predict( train, test, label_cols, 'Winner', models[model_name])\n",
    "        results[model_name] = acc\n",
    "    best = max( results.keys(), key=(lambda k: results[k]) )\n",
    "    print(year, best, results[best])\n",
    "    years[year] = (best, results[best])\n",
    "print()\n",
    "\n",
    "# LOOK AT IF IT IS GETTING EASIER OR HARDER TO PREDICT THE RESULTS ###\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.scatter( [year for year in years.keys()], [years[year][1] for year in years.keys()] )\n",
    "    \n",
    "# PRINT THE DATA TO MAKE SURE IT ALL LOOKS RIGHT #####################\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg :  0.709523809524\n",
      "DecisionTree :  0.660204081633\n",
      "NaiveBayes :  0.681292517007\n",
      "NeuralNet :  0.710884353741\n",
      "RandomForest :  0.671768707483\n",
      "KNN :  0.68537414966\n",
      "SVC :  0.69693877551\n",
      "BoostClassifier :  0.688775510204\n",
      "Ensemble:  0.728231292517\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COL1</th>\n",
       "      <th>COL2</th>\n",
       "      <th>DOL1</th>\n",
       "      <th>DOL2</th>\n",
       "      <th>LBIH</th>\n",
       "      <th>LBOB</th>\n",
       "      <th>LCNG</th>\n",
       "      <th>LDOK</th>\n",
       "      <th>LDUN</th>\n",
       "      <th>LMAS</th>\n",
       "      <th>...</th>\n",
       "      <th>WLK2</th>\n",
       "      <th>WMAS</th>\n",
       "      <th>WPGH</th>\n",
       "      <th>WPIG</th>\n",
       "      <th>WSE</th>\n",
       "      <th>WSEL</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WWIL</th>\n",
       "      <th>WWOL</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722603</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.853047</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>234.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.489726</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>151.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.139623</td>\n",
       "      <td>0.071685</td>\n",
       "      <td>0.157191</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.253425</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>85.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>56.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031469</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       COL1      COL2      DOL1      DOL2   LBIH   LBOB  LCNG  LDOK   LDUN  \\\n",
       "0  0.722603  0.800000  0.853047  0.859532  234.0  239.0   NaN   NaN  247.0   \n",
       "1  0.489726  0.003774  0.555556  0.003344  151.0  158.0   NaN   NaN  110.0   \n",
       "2  0.061644  0.139623  0.071685  0.157191   19.0   22.0   NaN   NaN   19.0   \n",
       "6  0.253425  0.037736  0.322581  0.026756   85.0   76.0   NaN   NaN   45.0   \n",
       "8  0.178082  0.052830  0.193548  0.036789   56.0   63.0   NaN   NaN   42.0   \n",
       "\n",
       "    LMAS   ...        WLK2   WMAS  WPGH  WPIG    WSE   WSEL  WTeamID  WWIL  \\\n",
       "0  249.0   ...    0.825175  265.0   NaN   NaN  210.0  233.0     1421   NaN   \n",
       "1  148.0   ...    0.003497    3.0   NaN   NaN    2.0    2.0     1112   NaN   \n",
       "2   18.0   ...    0.115385   40.0   NaN   NaN   44.0   34.0     1113   NaN   \n",
       "6   84.0   ...    0.013986   10.0   NaN   NaN   12.0    8.0     1181   NaN   \n",
       "8   51.0   ...    0.031469   11.0   NaN   NaN   16.0   10.0     1228   NaN   \n",
       "\n",
       "   WWOL  Winner  \n",
       "0   220       B  \n",
       "1     2       B  \n",
       "2    39       B  \n",
       "6     9       B  \n",
       "8    14       B  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASIC TESTING ON DIFFERENT TEAM STRENGTH RANKINGS ##############\n",
    "# I THINK WE CAN ADD PRE-PROCESSING BUT THIS LOOKS DECENT FOR NOW...\n",
    "data = pandas.read_csv( 'cleaned/TourneyResultsWithRankings.csv' )\n",
    "\n",
    "# WHAT FEATURES ARE WE INTERESTED IN? ############################\n",
    "systems = [ 'RPI', 'POM', 'MOR', 'RTH', 'WLK', 'DOL', 'COL', 'SAG' ]\n",
    "\n",
    "# SET UP THE RULES FOR RENAMING SO THAT THE WINNER DATA CAN BE #######\n",
    "# SCRAMBLED ##########################################################\n",
    "rules = []\n",
    "for col in systems:\n",
    "    rules.append( ('W' + col, 'L' + col, col) )\n",
    "\n",
    "# SCRAMBLE THE WINNER FROM THE DATA ##################################\n",
    "data = scramble_winner( data, rules )\n",
    "\n",
    "# SET UP MY LABEL COLUMNS ############################################\n",
    "label_cols = []\n",
    "for name in systems:\n",
    "    label_cols.append( name + '1' )\n",
    "    label_cols.append( name + '2' )\n",
    "    \n",
    "# NORMALIZE MY DATA ##################################################\n",
    "data = normalize(data, label_cols)\n",
    "    \n",
    "# TEST THE DATA ######################################################\n",
    "test_models( data, label_cols, 'Winner' )\n",
    "test_ensemble( ['LogReg', 'NeuralNet', 'SVC'], data, label_cols, 'Winner' )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg :  0.717952755906\n",
      "DecisionTree :  0.702519685039\n",
      "NaiveBayes :  0.711496062992\n",
      "NeuralNet :  0.714330708661\n",
      "RandomForest :  0.697637795276\n",
      "KNN :  0.67905511811\n",
      "SVC :  0.69905511811\n",
      "BoostClassifier :  0.709763779528\n",
      "Ensemble:  0.705039370079\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BetterSeedWon</th>\n",
       "      <th>LScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed1</th>\n",
       "      <th>Seed2</th>\n",
       "      <th>SeedDiff</th>\n",
       "      <th>WScore</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>1396</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>1207</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>1210</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1207</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>1425</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>-1</td>\n",
       "      <td>58</td>\n",
       "      <td>1229</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "      <td>1449</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-7</td>\n",
       "      <td>66</td>\n",
       "      <td>1246</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>1424</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-8</td>\n",
       "      <td>64</td>\n",
       "      <td>1246</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BetterSeedWon  LScore  LTeamID  Season     Seed1     Seed2  SeedDiff  \\\n",
       "4            True      46     1396    1985  0.466667  0.000000         7   \n",
       "6            True      54     1210    1985  0.066667  0.000000         1   \n",
       "8           False      55     1425    1985  0.466667  0.533333        -1   \n",
       "10          False      58     1449    1985  0.266667  0.733333        -7   \n",
       "11          False      61     1424    1985  0.200000  0.733333        -8   \n",
       "\n",
       "    WScore  WTeamID Winner  \n",
       "4       63     1207      B  \n",
       "6       60     1207      B  \n",
       "8       58     1229      B  \n",
       "10      66     1246      B  \n",
       "11      64     1246      B  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASIC TESTING ON SEEDING DATA ##################################\n",
    "data = pandas.read_csv( 'cleaned/TourneyResultsWithSeeds.csv')\n",
    "\n",
    "# WHAT FEATURES ARE WE INTERESTED IN? ############################\n",
    "columns = [ 'Seed' ]\n",
    "\n",
    "# SET UP THE RULES FOR RENAMING SO THAT THE WINNER DATA CAN BE #######\n",
    "# SCRAMBLED ##########################################################\n",
    "rules = []\n",
    "for col in columns:\n",
    "    rules.append( ('W' + col, 'L' + col, col) )\n",
    "\n",
    "# SCRAMBLE THE WINNER FROM THE DATA ##################################\n",
    "data = scramble_winner( data, rules )\n",
    "\n",
    "# SET UP MY LABEL COLUMNS ############################################\n",
    "label_cols = []\n",
    "for name in columns:\n",
    "    label_cols.append( name + '1' )\n",
    "    label_cols.append( name + '2' )\n",
    "    \n",
    "# NORMALIZE MY DATA ##################################################\n",
    "data = normalize(data, label_cols)\n",
    "    \n",
    "# TEST THE DATA ######################################################\n",
    "test_models( data, label_cols, 'Winner' )\n",
    "test_ensemble( ['LogReg', 'NeuralNet', 'SVC'], data, label_cols, 'Winner' )\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
